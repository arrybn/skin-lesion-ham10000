{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a909cc44-f8fc-40a4-9930-1432f433405a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our aim is to build a product to help doctors identifying the lesions. The system should be end-to-end, meaning that the input is 2000 hi-res images from the scanner, and the output is all the lesions and suspicios places from the body surface with the possibility of categorization: classified lesions of certain categories, lesions similar to a certain one, all lesions from the body. Because it's the helping tool for thr doctors to make the better decisions, we need to provide them with as much information as possible. That also means, each image patch we show should be also annotated with the position on the body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793d3b5-eb48-4388-9f67-57828dbbb6ee",
   "metadata": {},
   "source": [
    "## Stage 1: 3D body scan\n",
    "\n",
    "As I described above, we need to provide each image patch with the position information. Without having 2000 scans matched to a body surface, it would not be possible. Another beneficial thing about havinf a textured 3D body model is we can use the information about location to better predict the lesions classes as well as better estimate the confidence of predictions, since it could be that some body parts are harder to scan or they could produce \"noisier\" samples.\n",
    "\n",
    "So, I would start with the task of 3D body mesh reconstruction. For this, we can split the task to two stages:\n",
    "1. Scans to 3D point cloud\n",
    "2. Fitting deformable body mesh to 3D point cloud\n",
    "\n",
    "### Scans to 3D point cloud\n",
    "For this issue, several approaches could be employed:\n",
    "\n",
    "- Photogrammetry\n",
    "- NeRFs\n",
    "- Gaussian Splatting\n",
    "\n",
    "Last two work well in case of missing data, reflections, glossy surfaces and other. First one is a well-known option, which could struggle though in the setting because it relies on well-recogizable keypoints, which probably could be not the case. Others require a GPU to produce the point cloud.\n",
    "\n",
    "I would try all the approaches to choose the one which gives better results. Using the synthetic 3D bodies, it's possible to get a quantitave estimation to decide better.\n",
    "\n",
    "### Fitting deformable body mesh to 3D point cloud\n",
    "\n",
    "After we have a point cloud, we need to fit a deformable body mesh to the point cloud. For this, we can detect some body keypoints from the individual scans and project them to the 3D point cloud, basically having them in 3D. After this, we need to solve an optimization task with deforming the 3D mesh but also considering that the 3D keypoints are estimated with the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd375c-4077-4978-8b70-b5e3c1a695a7",
   "metadata": {},
   "source": [
    "## Stage 2: The first prototype. Skin/no-skin segmentation\n",
    "\n",
    "It's important to get the first prototype as soon as possible. Having it, we can better understand the data we need to collect and label and refine the reqiurements for the product, which could change our decisions about the tech stack we are using.\n",
    "\n",
    "We have no data so far and we want to get the prototype as fast as we can. For this, I would suggest using the segmentation based on color.\n",
    "It could be just having all the pixel colors (Hue channel from HSV color space) from the body surface and taking median as the skin color.\n",
    "\n",
    "It's obvoius, that we need to have many heuristics to get it working even for the several patients scans we would have in the beginning.\n",
    "Because background and the clothing will have the different color comparing to the skin, as the lesions. So, we need to separate lesions from others.\n",
    "\n",
    "But as a result, we would have the end-to-end system and would be able to make first iteration.\n",
    "\n",
    "Having this, we can try to establish the metrics for the product. Like, number of total lesions, accuracy of the skin/lesion classification, cost of one scan processing, maintaince cost of the product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2d005-e11b-4b5f-bf60-06432350e879",
   "metadata": {},
   "source": [
    "## Stage 3: Better no-skin detector\n",
    "\n",
    "I assume that most of the images will contain just skin, and lesions are reare comparing to skin surface\n",
    "It's possible to use anomaly detection approach with VAE to get skin/no skin labels\n",
    "Now we can distinguish between skin and no skin. To estimate the prediction performance, we need to label some amount of patches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844dab6-f4b8-482b-b1b6-f587c5df5575",
   "metadata": {},
   "source": [
    "## Stage 4: Lesion detector\n",
    "\n",
    "Now we have non-skin patches. Among these, there should be 3 well visually distinct classes: background, clothing, lesion. So, probably we could separate lesions from other classes by clusterization. Having this, we end up with the system which could spot the lesions in the scans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b8d99-3ef3-4495-9bea-ce46e422265d",
   "metadata": {},
   "source": [
    "## Stage 5: Lesion classificator\n",
    "\n",
    "\n",
    "Right now, we need to label the data. But because we can spot the lesions, it should eaiser and cheaper to get the decent numbers of labelled samples, because we ask to label only the relevant data (lesion samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf724c-0c3f-4ebd-9050-b926b1241fde",
   "metadata": {},
   "source": [
    "## Stage 5: ML system in production\n",
    "\n",
    "In order to have the ML in production, it's necessary to have a system to manage new data, train new models, deploy the models and check the performance. The good example of kind of this system is MLFlow. It will let resolve all these points and build the reliable automated solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
